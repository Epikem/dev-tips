# TIL 2020-08-14

오늘 배운 것 & 한 것

--------------------------

## 어제 한 일
- [x] 서버 api 버그픽스
- [x] 백준 강의 수강

## 할 일
- [ ] 서버 테스트 케이스 추가하기
- [ ] 테스트 파이프라인 구축
- [ ] 그래프 알고리즘 설계
- [ ] bada_audio 알고리즘 개선
- [x] stretch_web_interface 실행 시도

### 나중
- [ ] cfn [ssm](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html#dynamic-references-ssm-secure-strings) 적용 고려
- [ ] cfn autoscaling 적용:
  - https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/example-templates-autoscaling.html
  - https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html


**중요**
- [ ] 기능 분석, 설계문서 작성

- [ ] 배스천 호스트 구조 상세문서 작성
- [ ] [aws cloudformation ec2 모범 시나리오](https://aws.amazon.com/ko/blogs/infrastructure-and-automation/best-practices-for-deploying-ec2-instances-with-aws-cloudformation/) 읽고 적용하기

- [ ] uml 시나리오 작성
- [ ] 예외사례 생각하기 (spoof, ddos 등)

### 
- [ ] cloudformer 사용불가 - 디딤나우 문의 otp 인증 필요

## 배운 것 & 한것 



### 캡스톤 web interface 저장소 분석

https://github.com/hello-robot/stretch_web_interface

돌려봤는데 카메라가 없어서 실행 전체가 어렵고 비밀번호 등이 바뀌었는지 웹에 로그인시 unauthorized가 뜸.

알고보니 설치가 중간에 멈춰서 다 안된거였음. 설치 스크립트 끝난 후 다시 실행하니 검은 화면 실행이 확인됨.

### 캡스톤 sound 리팩토링

https://news.sbs.co.kr/news/endPage.do?news_id=N0311686453
https://github.com/ShichengChen/Audio-Source-Separation
https://github.com/introlab/odas/wiki/Installation

- [ ] 코드 리팩토링
- [ ] 사운드 추가 기준 살펴보기
- [ ] 사운드 소리 인식 개선
- [ ] 사운드 방향 인식 개선

#### 사운드 개선

전체적 코드 정리는 그렇다 치고, 현재 문제들을 조금 분석해보자.
1. 다중 음원의 소리와 방향의 개별 구별 불가
- odas에서는 sound tracking, sound separation 등도 지원되는듯 한데, respeaker ROS node 에서는 없는거 같다.
2. 소리 방향: 정확도 떨어짐
-> 그때 생각했던 방식은 방향을 정확하게 인식한다는 전제였음. 그게 아니라 만약 소리 방향으로 가려면 조금씩 전진해야할 듯 함. 문제는 그동안 소리가 지속되어야하고, 지속되었을때 위상차가 사라져버리는 소리가 아니어야함.
3. 소리 방향: 시간이 고려되어있지 않음. 콜백에 기반하여 리스피커에서 내주는 방향을 평균처리하는건데, 그래서 시간적으로 이게 얼마나 안정화된 방향인지 알 수가 없음. 소리에 따라 아예 반대로 오랫동안 인식하는 경우도 있음.
4. 소리 인식: 간섭 소리 있을때 인식률 떨어짐.
5. 소리 인식: 외국기준이어서 한국 초인종 소리는 음악으로 인식해버림
6. 소리 인식: 알람소리 같은거 말고 초인종 소리 등 여러 번 발생하기 힘든 경우도 있음.
7. 소리 인식: 일반적인 분류의 확률이 대부분 구체적인 분류보다 높게 나옴.
8. 소리 인식: 멀리있으면 거의 안됨. -> 파형 증폭?

- 선풍기 틀어보니 일정하게 반대쪽으로 인식하기도 함.
- 초인종 녹음해서 틀어보니 처음엔 잘 인식하다가 방향 살짝 바꾸면 방향이 막 튐
- 큰 tv소리와 작은 물끓는 소리 등이 같이 나면 인식될 수가 없다.
- 말소리는 기가 막히게 잘 분류한다.

아예 웹에 중요 사물 위치를 등록하여 그런 소리가 난 것 같으면 그쪽으로 가게 하는것도 방법이겠다. 그러나 소리가 일정 이상으로 작으면 그냥 노이즈 분류가 되서 그걸 인식하자니 오류인식률이 너무 늘어날 가능성이 있다. 무엇보다 관련 분류가 그냥 0으로 뜬다.

#### 사운드 추가 기준

https://news.sbs.co.kr/news/endPage.do?news_id=N0311686453
- 전자레인지 소리 : 몇 번 안나므로 어렵다. `Microwave oven` 분류가 있기는 함.
그러나 끝나는 소리에 대한 것은 아님. 그냥 `Beep bleep`에 가까움.
- 초인종 소리
- 사람이 부르는 소리 : speech와 구별 어려움.
- wafeform abs 평균 내보니 크기가 매우 작음.

#### 사운드 소리 인식 개선

시간 긴것과 짧은것을 구별하여 실행하는것이 목표.

그러려면 각 키마다 예상되는 기간 단위를 생각해야 한다.
기본 단위를 1초로 하여, 1초 단위로 정보를 저장하고 읽되, 이동 평균 방식으로 여러 큐를 관리하여 소리를 각기 다른 길이로 읽게 한다.
생각할 점은, 긴 인식들의 경우 겹치게 하느냐 마느냐인데, 그건 크게 상관은 없을 듯 하다. 애초에 이 알고리즘적 개선으로 위의 핵심 문제들을 개선하기가 어려워 보인다.

그래도 일단은 적용해보자.

일단 두개의 큐를 만드는건 쉬운데, 스코어 구해서 처리해서 따로 출력하는부분은 어떻게 하나?? 사실 제대로 하려면 두 개의 큐가 아니라 키마다 초단위로 길이를 파라미터로 할 수 있게 할 생각이지만, 먼저 두개만 해서 해보자.

일단 주기는 short기준으로 실행하되, 다음과 같이 되어야 한다:
- 만약 longQueue에 쌓인 길이가 기준 이상이라면 해당 Queue로부터 꺼내서 waveform을 만들고, 모델 돌려서 스코어 구하고 확률을 구한다.
- 그렇지 않으면 longQueue는 냅둔다.
- shortQueue도 같은 방식으로 처리한다.

이렇게 하면 확률이 두 번 따로 나오게 되는데, 이를 어떻게 출력시키나??
일단 short기준으로 출력시키되, longq가 업데이트되지 않는 경우 변화가 없으므로 상관없을지도.

적용해봤는데 사실 큰 차이는 모르겠다. 알람은 원래 특정 소리에 대해서는 잘 되던 것이고, boil과 water는 여전히 구별이 안 된다.

#### 사운드 방향 인식 개선


## tags
- \#TIL, \#blog, \#vscode, \#prj

--------------------------